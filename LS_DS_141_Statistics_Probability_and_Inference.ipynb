{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_141_Statistics_Probability_and_Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "29PHHhLFLYBB",
        "g9Hf2QOJ9p2M",
        "Hsd2R0b--cgx",
        "FMhDKOFND0qY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed-chin-git/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/LS_DS_141_Statistics_Probability_and_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eJGtmni-DezY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science Module 141 MONDAY\n",
        "## Statistics, Probability, and Inference"
      ]
    },
    {
      "metadata": {
        "id": "29PHHhLFLYBB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference Materials\n",
        "[definition of Frequentist inference](https://en.wikipedia.org/wiki/Frequentist_inference)\n",
        "\n",
        "[Null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis)\n",
        "\n",
        "[Understanding the t-distribution and its normal approximation ](https://rpsychologist.com/d3/tdist/)\n",
        "\n",
        "[Student's t-Distribution](https://homepage.stat.uiowa.edu/~mbognar/applets/t.html)\n",
        "\n",
        "[stats package from SciPy](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html).\n",
        "\n",
        "[LECTURE: Probability, Statistics, and Inference with Aaron Gallant](https://www.youtube.com/watch?time_continue=3&v=drcOsL4NbR4)\n",
        "\n",
        "[Hypothesis Testing - Proportion Example](https://www.youtube.com/watch?v=5LFhu0vGzkI)\n",
        "\n",
        "[T Statistic: Definition, Types and Comparison to Z Score](https://www.statisticshowto.datasciencecentral.com/t-statistic/)\n",
        "\n",
        "\n",
        "###Can We Accept the Null Hypothesis?\n",
        "Some researchers say that a hypothesis test can have one of two outcomes: you accept the null hypothesis or you reject the null hypothesis. Many statisticians, however, take issue with the notion of \"accepting the null hypothesis.\" Instead, they say: you reject the null hypothesis or you fail to reject the null hypothesis.\n",
        "\n",
        "Why the distinction between \"acceptance\" and \"failure to reject?\" Acceptance implies that the null hypothesis is true. Failure to reject implies that the data are not sufficiently persuasive for us to prefer the alternative hypothesis over the null hypothesis.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zx2zO8OHsMHp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ]
    },
    {
      "metadata": {
        "id": "Mz-2osISsHiG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9Hf2QOJ9p2M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####BInary Search       Code challenge\n",
        "Can you do this with O(lg n) runtime complexity?\n",
        "\n",
        "[What does the time complexity O(log n) actually mean?](https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf)\n",
        "\n",
        "[Whatâ€™s the simple explanation for O(n log n) ? ](https://www.quora.com/What%E2%80%99s-the-simple-explanation-for-O-n-log-n)\n",
        "]\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "998db50e-76fc-40c0-8108-c110292f4a12",
        "id": "Erx_tz9o7k9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "def find_rotation_point(words):\n",
        "  first_word = words[0]\n",
        "  floor_index = 0\n",
        "  ceiling_index = int(len(words) - 1)\n",
        "\n",
        "  while floor_index < ceiling_index:\n",
        "      # Guess a point halfway between floor and ceiling\n",
        "      guess_index = int(floor_index + ((ceiling_index - floor_index) / 2))\n",
        "      # If guess comes after first word or is the first word\n",
        "      if words[guess_index] >= first_word:\n",
        "          # Go right\n",
        "          floor_index = guess_index\n",
        "      else:\n",
        "          # Go left\n",
        "          ceiling_index = guess_index\n",
        "\n",
        "      # If floor and ceiling have converged\n",
        "      if floor_index + 1 == ceiling_index:\n",
        "          # Between floor and ceiling is where we flipped to the beginning\n",
        "          # so ceiling is alphabetically first\n",
        "          return ceiling_index\n",
        "\n",
        "words = [\n",
        "    'ptolemaic',\n",
        "    'retrograde',\n",
        "    'supplant',\n",
        "    'undulate',\n",
        "    'xenoepist',\n",
        "    'asymptote',  #---this rotation point  print out # 5\n",
        "    'babka',\n",
        "    'banoffee',\n",
        "    'engender',\n",
        "    'karpatka',\n",
        "    'othellolagkage']\n",
        "\n",
        "print (find_rotation_point(words))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hsd2R0b--cgx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Using   df .map    to encode strings into ordinals(ints)"
      ]
    },
    {
      "metadata": {
        "id": "-If_mqUyt0d9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "columns = ['carat', 'cut', 'price']\n",
        "\n",
        "train = pd.DataFrame(columns=columns, \n",
        "        data=[[0.3, 'Ideal', 422],\n",
        "        [0.31, 'Ideal', 489],\n",
        "        [0.42, 'Premium', 737],\n",
        "        [0.5, 'Ideal', 1415],\n",
        "        [0.51, 'Premium', 1177],\n",
        "        [0.7, 'Fair', 1865],\n",
        "        [0.73, 'Fair', 2351],\n",
        "        [1.01, 'Good', 3768],\n",
        "        [1.18, 'Very Good', 3965],\n",
        "        [1.18, 'Ideal', 4838]])\n",
        "\n",
        "test  = pd.DataFrame(columns=columns, \n",
        "        data=[[0.3, 'Ideal', 432],\n",
        "        [0.34, 'Ideal', 687],\n",
        "        [0.37, 'Premium', 1124],\n",
        "        [0.4, 'Good', 720],\n",
        "        [0.51, 'Ideal', 1397],\n",
        "        [0.51, 'Very Good', 1284],\n",
        "        [0.59, 'Ideal', 1437],\n",
        "        [0.7, 'Ideal', 3419],\n",
        "        [0.9, 'Premium', 3484],\n",
        "        [0.9, 'Fair', 2964]])\n",
        "\n",
        "# encode strings into ordinals\n",
        "cut_levels = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n",
        "train.cut = train.cut.map(cut_levels)\n",
        "test.cut = test.cut.map(cut_levels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMhDKOFND0qY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare - examine what's available in SciPy\n",
        "\n",
        "As we delve into statistics, we'll be using more libraries - in particular the [stats package from SciPy](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html)."
      ]
    },
    {
      "metadata": {
        "id": "fQ9rkLJmEbsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4253
        },
        "outputId": "eb14cb77-9d25-48ed-90e0-417afac4f50a"
      },
      "cell_type": "code",
      "source": [
        "##  from scipy import stats  above\n",
        "dir(stats)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_binned_statistic',\n",
              " '_constants',\n",
              " '_continuous_distns',\n",
              " '_discrete_distns',\n",
              " '_distn_infrastructure',\n",
              " '_distr_params',\n",
              " '_multivariate',\n",
              " '_stats',\n",
              " '_stats_mstats_common',\n",
              " '_tukeylambda_stats',\n",
              " 'absolute_import',\n",
              " 'alpha',\n",
              " 'anderson',\n",
              " 'anderson_ksamp',\n",
              " 'anglit',\n",
              " 'ansari',\n",
              " 'arcsine',\n",
              " 'argus',\n",
              " 'bartlett',\n",
              " 'bayes_mvs',\n",
              " 'bernoulli',\n",
              " 'beta',\n",
              " 'betaprime',\n",
              " 'binned_statistic',\n",
              " 'binned_statistic_2d',\n",
              " 'binned_statistic_dd',\n",
              " 'binom',\n",
              " 'binom_test',\n",
              " 'boltzmann',\n",
              " 'boxcox',\n",
              " 'boxcox_llf',\n",
              " 'boxcox_normmax',\n",
              " 'boxcox_normplot',\n",
              " 'bradford',\n",
              " 'burr',\n",
              " 'burr12',\n",
              " 'cauchy',\n",
              " 'chi',\n",
              " 'chi2',\n",
              " 'chi2_contingency',\n",
              " 'chisquare',\n",
              " 'circmean',\n",
              " 'circstd',\n",
              " 'circvar',\n",
              " 'combine_pvalues',\n",
              " 'contingency',\n",
              " 'cosine',\n",
              " 'crystalball',\n",
              " 'cumfreq',\n",
              " 'describe',\n",
              " 'dgamma',\n",
              " 'dirichlet',\n",
              " 'distributions',\n",
              " 'division',\n",
              " 'dlaplace',\n",
              " 'dweibull',\n",
              " 'energy_distance',\n",
              " 'entropy',\n",
              " 'erlang',\n",
              " 'expon',\n",
              " 'exponnorm',\n",
              " 'exponpow',\n",
              " 'exponweib',\n",
              " 'f',\n",
              " 'f_oneway',\n",
              " 'fatiguelife',\n",
              " 'find_repeats',\n",
              " 'fisher_exact',\n",
              " 'fisk',\n",
              " 'fligner',\n",
              " 'foldcauchy',\n",
              " 'foldnorm',\n",
              " 'frechet_l',\n",
              " 'frechet_r',\n",
              " 'friedmanchisquare',\n",
              " 'gamma',\n",
              " 'gausshyper',\n",
              " 'gaussian_kde',\n",
              " 'genexpon',\n",
              " 'genextreme',\n",
              " 'gengamma',\n",
              " 'genhalflogistic',\n",
              " 'genlogistic',\n",
              " 'gennorm',\n",
              " 'genpareto',\n",
              " 'geom',\n",
              " 'gilbrat',\n",
              " 'gmean',\n",
              " 'gompertz',\n",
              " 'gumbel_l',\n",
              " 'gumbel_r',\n",
              " 'halfcauchy',\n",
              " 'halfgennorm',\n",
              " 'halflogistic',\n",
              " 'halfnorm',\n",
              " 'hmean',\n",
              " 'hypergeom',\n",
              " 'hypsecant',\n",
              " 'invgamma',\n",
              " 'invgauss',\n",
              " 'invweibull',\n",
              " 'invwishart',\n",
              " 'iqr',\n",
              " 'itemfreq',\n",
              " 'jarque_bera',\n",
              " 'johnsonsb',\n",
              " 'johnsonsu',\n",
              " 'kappa3',\n",
              " 'kappa4',\n",
              " 'kde',\n",
              " 'kendalltau',\n",
              " 'kruskal',\n",
              " 'ks_2samp',\n",
              " 'ksone',\n",
              " 'kstat',\n",
              " 'kstatvar',\n",
              " 'kstest',\n",
              " 'kstwobign',\n",
              " 'kurtosis',\n",
              " 'kurtosistest',\n",
              " 'laplace',\n",
              " 'levene',\n",
              " 'levy',\n",
              " 'levy_l',\n",
              " 'levy_stable',\n",
              " 'linregress',\n",
              " 'loggamma',\n",
              " 'logistic',\n",
              " 'loglaplace',\n",
              " 'lognorm',\n",
              " 'logser',\n",
              " 'lomax',\n",
              " 'mannwhitneyu',\n",
              " 'matrix_normal',\n",
              " 'maxwell',\n",
              " 'median_test',\n",
              " 'mielke',\n",
              " 'mode',\n",
              " 'moment',\n",
              " 'mood',\n",
              " 'morestats',\n",
              " 'moyal',\n",
              " 'mstats',\n",
              " 'mstats_basic',\n",
              " 'mstats_extras',\n",
              " 'multinomial',\n",
              " 'multivariate_normal',\n",
              " 'mvn',\n",
              " 'mvsdist',\n",
              " 'nakagami',\n",
              " 'nbinom',\n",
              " 'ncf',\n",
              " 'nct',\n",
              " 'ncx2',\n",
              " 'norm',\n",
              " 'normaltest',\n",
              " 'norminvgauss',\n",
              " 'obrientransform',\n",
              " 'ortho_group',\n",
              " 'pareto',\n",
              " 'pearson3',\n",
              " 'pearsonr',\n",
              " 'percentileofscore',\n",
              " 'planck',\n",
              " 'pointbiserialr',\n",
              " 'poisson',\n",
              " 'power_divergence',\n",
              " 'powerlaw',\n",
              " 'powerlognorm',\n",
              " 'powernorm',\n",
              " 'ppcc_max',\n",
              " 'ppcc_plot',\n",
              " 'print_function',\n",
              " 'probplot',\n",
              " 'randint',\n",
              " 'random_correlation',\n",
              " 'rankdata',\n",
              " 'ranksums',\n",
              " 'rayleigh',\n",
              " 'rdist',\n",
              " 'recipinvgauss',\n",
              " 'reciprocal',\n",
              " 'relfreq',\n",
              " 'rice',\n",
              " 'rv_continuous',\n",
              " 'rv_discrete',\n",
              " 'rv_histogram',\n",
              " 'scoreatpercentile',\n",
              " 'sem',\n",
              " 'semicircular',\n",
              " 'shapiro',\n",
              " 'sigmaclip',\n",
              " 'skellam',\n",
              " 'skew',\n",
              " 'skewnorm',\n",
              " 'skewtest',\n",
              " 'spearmanr',\n",
              " 'special_ortho_group',\n",
              " 'statlib',\n",
              " 'stats',\n",
              " 't',\n",
              " 'test',\n",
              " 'theilslopes',\n",
              " 'tiecorrect',\n",
              " 'tmax',\n",
              " 'tmean',\n",
              " 'tmin',\n",
              " 'trapz',\n",
              " 'triang',\n",
              " 'trim1',\n",
              " 'trim_mean',\n",
              " 'trimboth',\n",
              " 'truncexpon',\n",
              " 'truncnorm',\n",
              " 'tsem',\n",
              " 'tstd',\n",
              " 'ttest_1samp',\n",
              " 'ttest_ind',\n",
              " 'ttest_ind_from_stats',\n",
              " 'ttest_rel',\n",
              " 'tukeylambda',\n",
              " 'tvar',\n",
              " 'uniform',\n",
              " 'unitary_group',\n",
              " 'variation',\n",
              " 'vonmises',\n",
              " 'vonmises_line',\n",
              " 'wald',\n",
              " 'wasserstein_distance',\n",
              " 'weibull_max',\n",
              " 'weibull_min',\n",
              " 'weightedtau',\n",
              " 'wilcoxon',\n",
              " 'wishart',\n",
              " 'wrapcauchy',\n",
              " 'zipf',\n",
              " 'zmap',\n",
              " 'zscore']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "bxW4SG_gJGlZ",
        "colab_type": "code",
        "outputId": "c8ffd64f-0d6e-4683-f753-f2a18ff33c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# As usual, lots of stuff here! There's our friend, the normal distribution\n",
        "norm = stats.norm()\n",
        "print(norm.mean())\n",
        "print(norm.std())\n",
        "print(norm.var())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RyNKPt_tJk86",
        "colab_type": "code",
        "outputId": "ab25d636-b84a-4c6a-cab8-1fa4429f9c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# And a new friend - t\n",
        "t1 = stats.t(5)  # 5 is df \"shape\" parameter\n",
        "print(t1.mean())\n",
        "print(t1.std())\n",
        "print(t1.var())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.2909944487358056\n",
            "1.6666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SRn1zMuaKgxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![T distribution PDF with different shape parameters](https://upload.wikimedia.org/wikipedia/commons/4/41/Student_t_pdf.svg)\n",
        "\n",
        "*(Picture from [Wikipedia](https://en.wikipedia.org/wiki/Student's_t-distribution#/media/File:Student_t_pdf.svg))*\n",
        "\n",
        "The t-distribution is \"normal-ish\" - the larger the parameter (which reflects its degrees of freedom - more input data/features will increase it), the closer to true normal."
      ]
    },
    {
      "metadata": {
        "id": "seQv5unnJvpM",
        "colab_type": "code",
        "outputId": "ba80fd8f-33fc-44b2-caf2-3aa1ec63b6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "t2 = stats.t(30)  # Will be closer to normal\n",
        "print(t2.mean())\n",
        "print(t2.std())\n",
        "print(t2.var())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0350983390135313\n",
            "1.0714285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOvEGMysLaE2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Why is it different from normal? To better reflect the tendencies of small data and situations with unknown population standard deviation. In other words, the normal distribution is still the nice pure ideal in the limit (thanks to the central limit theorem), but the t-distribution is much more useful in many real-world situations.\n",
        "\n",
        "History sidenote - this is \"Student\":\n",
        "\n",
        "![William Sealy Gosset](https://upload.wikimedia.org/wikipedia/commons/4/42/William_Sealy_Gosset.jpg)\n",
        "\n",
        "*(Picture from [Wikipedia](https://en.wikipedia.org/wiki/File:William_Sealy_Gosset.jpg))*\n",
        "\n",
        "His real name is William Sealy Gosset, and he published under the pen name \"Student\" because he was not an academic. He was a brewer, working at Guinness and using trial and error to determine the best ways to yield barley. He's also proof that, even 100 years ago, you don't need official credentials to do real data science!"
      ]
    },
    {
      "metadata": {
        "id": "1yx_QilAEC6o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Live Lecture - let's perform and interpret a t-test\n",
        "\n",
        "We'll generate our own data, so we can know and alter the \"ground truth\" that the t-test should find. We will learn about p-values and how to interpret \"statistical significance\" based on the output of a hypothesis test."
      ]
    },
    {
      "metadata": {
        "id": "vIvxgnPRrhjz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### In Class\n",
        "\n",
        "who likes Pepsi or Coke   (0 or 1) \n"
      ]
    },
    {
      "metadata": {
        "id": "BuysRPs-Ed0v",
        "colab_type": "code",
        "outputId": "40ec5149-de27-468b-bb7e-398dd2182ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "survey_data = [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
        "               0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
        "               1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0]\n",
        "df=pd.DataFrame(survey_data)\n",
        "df.describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.478518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0\n",
              "count  50.000000\n",
              "mean    0.660000\n",
              "std     0.478518\n",
              "min     0.000000\n",
              "25%     0.000000\n",
              "50%     1.000000\n",
              "75%     1.000000\n",
              "max     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "lS3n7kHaOKCc",
        "colab_type": "code",
        "outputId": "31136bff-154b-4b98-851f-c65fb7622328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "df.plot.hist()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4584e5898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4KyEZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe4337ef780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5XZOj1EXOSgb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Reject the Null hypothesis"
      ]
    },
    {
      "metadata": {
        "id": "hZk9t0Q1rg23",
        "colab_type": "code",
        "outputId": "eae8ddf8-f396-4c4b-dd45-d6bfe73e5f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Now with confidence!\n",
        "\n",
        "import scipy\n",
        "scipy.stats.ttest_1samp(survey_data, 0.5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_1sampResult(statistic=2.364321853156195, pvalue=0.02207003200903075)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "NOGhU-KkrgtL",
        "colab_type": "code",
        "outputId": "66a8cacc-82e4-4dc4-8978-48d2843c1a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# the t-statistic is the ratio of the departure of the estimated value of  a\n",
        "# parameter from its hypothesized value to its standard error\n",
        "\n",
        "# We want to calculate: tstat = 2.364321853156195\n",
        "std_dev=0.478518\n",
        "sample_size=len(survey_data)\n",
        "sample_stderr = std_dev/ np.sqrt(sample_size)\n",
        "sample_mean = 0.660000\n",
        "null_hypothesis_mean = 0.5\n",
        "\n",
        "t_stat = (sample_mean - null_hypothesis_mean) / sample_stderr\n",
        "print(t_stat)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.364322449518046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7MAanvO0U4G0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Reproduce it"
      ]
    },
    {
      "metadata": {
        "id": "MQ3DQHCJU731",
        "colab_type": "code",
        "outputId": "09e667f9-204a-44d6-dfec-1f10110a7821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "def make_soda_data(n=50):\n",
        "  return pd.DataFrame([random.randint(0,1) for _ in range(n)])\n",
        "make_soda_data().describe()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.504672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0\n",
              "count  50.000000\n",
              "mean    0.480000\n",
              "std     0.504672\n",
              "min     0.000000\n",
              "25%     0.000000\n",
              "50%     0.000000\n",
              "75%     1.000000\n",
              "max     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "KjGjmloUU7o_",
        "colab_type": "code",
        "outputId": "3533d6ba-3881-4e41-9d87-ec76f5419fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "t_statistics = []\n",
        "p_values = []\n",
        "n_experiments = 10000\n",
        "\n",
        "for _ in range(n_experiments):\n",
        "  df = make_soda_data(n=500)\n",
        "  ttest = scipy.stats.ttest_1samp(df, 0.5)\n",
        "  t_statistics.append(ttest.statistic)\n",
        "  p_values.append(ttest.pvalue)\n",
        "\n",
        "pd.DataFrame(t_statistics).describe()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.014043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.997863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.527969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.625718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.648086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.620776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  10000.000000\n",
              "mean       0.014043\n",
              "std        0.997863\n",
              "min       -3.527969\n",
              "25%       -0.625718\n",
              "50%        0.000000\n",
              "75%        0.648086\n",
              "max        3.620776"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "qY-LL8pTZ9AA",
        "colab_type": "code",
        "outputId": "52204932-9494-489e-87ee-1031427bebeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(p_values).describe()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.503580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.290978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.245318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.531786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.788749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  10000.000000\n",
              "mean       0.503580\n",
              "std        0.290978\n",
              "min        0.000324\n",
              "25%        0.245318\n",
              "50%        0.531786\n",
              "75%        0.788749\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "egXb7YpqEcZF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - apply the t-test to real data\n",
        "\n",
        "Your assignment is to determine which issues have \"statistically significant\" differences between political parties in this [1980s congressional voting data](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records). The data consists of 435 instances (one for each congressperson), a class (democrat or republican), and 16 binary attributes (yes or no for voting for or against certain issues). Be aware - there are missing values!\n",
        "\n",
        "Your goals:\n",
        "\n",
        "1. Load and clean the data (or determine the best method to drop observations when running tests)\n",
        "2. Using hypothesis testing, find an issue that democrats support more than republicans with p < 0.01\n",
        "3. Using hypothesis testing, find an issue that republicans support more than democrats with p < 0.01\n",
        "4. Using hypothesis testing, find an issue where the difference between republicans and democrats has p > 0.1 (i.e. there may not be much of a difference)\n",
        "\n",
        "Note that this data will involve *2 sample* t-tests, because you're comparing averages across two groups (republicans and democrats) rather than a single group against a null hypothesis.\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "1. Refactor your code into functions so it's easy to rerun with arbitrary variables\n",
        "2. Apply hypothesis testing to your personal project data (for the purposes of this notebook you can type a summary of the hypothesis you formed and tested)"
      ]
    },
    {
      "metadata": {
        "id": "1On_pkLCroeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preliminary Data Analysis\n",
        "[from here](https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data)\n",
        "4. Relevant Information:\n",
        "      This data set includes votes for each of the U.S. House of\n",
        "      Representatives Congressmen on the 16 key votes identified by the\n",
        "      CQA.  The CQA lists nine different types of votes: voted for, paired\n",
        "      for, and announced for (these three simplified to yea), voted\n",
        "      against, paired against, and announced against (these three\n",
        "      simplified to nay), voted present, voted present to avoid conflict\n",
        "      of interest, and did not vote or otherwise make a position known\n",
        "      (these three simplified to an unknown disposition).\n",
        "\n",
        "5. Number of Instances: 435 (267 democrats, 168 republicans)\n",
        "\n",
        "6. Number of Attributes: 16 + class name = 17 (all Boolean valued)"
      ]
    },
    {
      "metadata": {
        "id": "nstrmCG-Ecyk",
        "colab_type": "code",
        "outputId": "a598a057-0def-41e2-acce-edb32c71d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "#  LOAD DATA\n",
        "data_url='https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data'\n",
        "df = pd.read_csv(data_url, header=None)\n",
        "print(df.shape)\n",
        "df.describe()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(435, 17)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>democrat</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>267</td>\n",
              "      <td>236</td>\n",
              "      <td>195</td>\n",
              "      <td>253</td>\n",
              "      <td>247</td>\n",
              "      <td>212</td>\n",
              "      <td>272</td>\n",
              "      <td>239</td>\n",
              "      <td>242</td>\n",
              "      <td>207</td>\n",
              "      <td>216</td>\n",
              "      <td>264</td>\n",
              "      <td>233</td>\n",
              "      <td>209</td>\n",
              "      <td>248</td>\n",
              "      <td>233</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0    1    2    3    4    5    6    7    8    9    10   11   12  \\\n",
              "count        435  435  435  435  435  435  435  435  435  435  435  435  435   \n",
              "unique         2    3    3    3    3    3    3    3    3    3    3    3    3   \n",
              "top     democrat    n    y    y    n    y    y    y    y    y    y    n    n   \n",
              "freq         267  236  195  253  247  212  272  239  242  207  216  264  233   \n",
              "\n",
              "         13   14   15   16  \n",
              "count   435  435  435  435  \n",
              "unique    3    3    3    3  \n",
              "top       y    y    n    y  \n",
              "freq    209  248  233  269  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "AkpMn6cWALnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "7. Attribute Information:\n",
        "   1. Class Name: 2 (democrat, republican)\n",
        "   2. handicapped-infants: 2 (y,n)\n",
        "   3. water-project-cost-sharing: 2 (y,n)\n",
        "   4. adoption-of-the-budget-resolution: 2 (y,n)\n",
        "   5. physician-fee-freeze: 2 (y,n)\n",
        "   6. el-salvador-aid: 2 (y,n)\n",
        "   7. religious-groups-in-schools: 2 (y,n)\n",
        "   8. anti-satellite-test-ban: 2 (y,n)\n",
        "   9. aid-to-nicaraguan-contras: 2 (y,n)\n",
        "  10. mx-missile: 2 (y,n)\n",
        "  11. immigration: 2 (y,n)\n",
        "  12. synfuels-corporation-cutback: 2 (y,n)\n",
        "  13. education-spending: 2 (y,n)\n",
        "  14. superfund-right-to-sue: 2 (y,n)\n",
        "  15. crime: 2 (y,n)\n",
        "  16. duty-free-exports: 2 (y,n)\n",
        "  17. export-administration-act-south-africa: 2 (y,n)\n",
        "\n",
        "8. Missing Attribute Values: Denoted by \"?\"\n",
        "\n",
        "   NOTE: It is important to recognize that \"?\" in this database does not mean that the value of the attribute is unknown.  It  means simply, that the value is not \"yea\" or \"nay\" (see  \"Relevant Information\" section above).\n",
        "\n",
        "9. Class Distribution: (2 classes)\n",
        "   1. 45.2 percent are democrat\n",
        "   2. 54.8 percent are republican"
      ]
    },
    {
      "metadata": {
        "id": "JFcnq1fdussG",
        "colab_type": "code",
        "outputId": "07316f35-595e-487d-df72-75aa925e9e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# clean the data\n",
        "\n",
        "# rename the columns/features\n",
        "column_names = {0 :\"party\",\n",
        "            1 : \"handicappedInfants\",\n",
        "            2 : \"water-project-cost-sharing\",\n",
        "            3 : \"adoption-of-the-budget-resolution\",\n",
        "            4 : \"physician-fee-freeze\",\n",
        "            5 : \"el-salvador-aid\",\n",
        "            6 : \"religious-groups-in-schools\",\n",
        "            7 : \"anti-satellite-test-ban\",\n",
        "            8 : \"aid-to-nicaraguan-contras\",\n",
        "            9 : \"mx-missile\",\n",
        "            10 : \"immigration\",\n",
        "            11 : \"synfuels-corporation-cutback\",\n",
        "            12 :\"education-spending\",\n",
        "            13 : \"superfund-right-to-sue\",\n",
        "            14 : \"crime\",\n",
        "            15 : \"duty-free-exports\",\n",
        "            16 : \"export-administration-act-south-africa\"}\n",
        "df.rename(column_names, axis='columns', inplace=True)\n",
        "\n",
        "#  encode ordinals\n",
        "df.replace(to_replace='?', value=np.nan, inplace=True) # replace ? with Nan\n",
        "df.replace(to_replace='y', value=1, inplace=True)  #  encode y = 1\n",
        "df.replace(to_replace='n', value=0, inplace=True)  # encode n = 0\n",
        "\n",
        "df.isnull().sum()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "party                                       0\n",
              "handicappedInfants                         12\n",
              "water-project-cost-sharing                 48\n",
              "adoption-of-the-budget-resolution          11\n",
              "physician-fee-freeze                       11\n",
              "el-salvador-aid                            15\n",
              "religious-groups-in-schools                11\n",
              "anti-satellite-test-ban                    14\n",
              "aid-to-nicaraguan-contras                  15\n",
              "mx-missile                                 22\n",
              "immigration                                 7\n",
              "synfuels-corporation-cutback               21\n",
              "education-spending                         31\n",
              "superfund-right-to-sue                     25\n",
              "crime                                      17\n",
              "duty-free-exports                          28\n",
              "export-administration-act-south-africa    104\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "2W9bwfjNlorG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dfdemocrat = df[df.party == \"democrat\"]\n",
        "dfrepublican = df[df.party == \"republican\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htl1bQSvdOQo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Perform Hypothesis Test on GOP issue : Crime"
      ]
    },
    {
      "metadata": {
        "id": "b1tEwT50mAOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "64321dfa-c25f-4b3b-b0df-99611a77fc40"
      },
      "cell_type": "code",
      "source": [
        "print('Dem votes for crime issues =',dfdemocrat.crime.sum(), 'out of',dfdemocrat.crime.shape[0])\n",
        "print('Rep votes for crime issues =',dfrepublican.crime.sum(), 'out of',dfrepublican.crime.shape[0])\n",
        "stats.ttest_ind(dfdemocrat['crime'],dfrepublican['crime'], nan_policy='omit',)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dem votes for crime issues = 90.0 out of 267\n",
            "Rep votes for crime issues = 158.0 out of 168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=-16.342085656197696, pvalue=9.952342705606092e-47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "IWGJ8venpZE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Perform Hypothesis Test on Dems issue : Handicapped Infants "
      ]
    },
    {
      "metadata": {
        "id": "G5i6Qosopk1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "797f0ca7-e260-4399-be93-475306d61ef9"
      },
      "cell_type": "code",
      "source": [
        "print('Dem votes for handicapped-infants issues =',dfdemocrat.handicappedInfants.sum(), 'out of',dfdemocrat.handicappedInfants.shape[0])\n",
        "print('Rep votes for handicapped-infants issues =',dfrepublican.handicappedInfants.sum(), 'out of',dfrepublican.handicappedInfants.shape[0])\n",
        "stats.ttest_ind(dfdemocrat['handicappedInfants'],dfrepublican['handicappedInfants'], nan_policy='omit',)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dem votes for handicapped-infants issues = 156.0 out of 267\n",
            "Rep votes for handicapped-infants issues = 31.0 out of 168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=9.205264294809222, pvalue=1.613440327937243e-18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "KmmUdN-owhBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What happens if samples are exactly the same"
      ]
    },
    {
      "metadata": {
        "id": "YHMIXkDDr3Zy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcf3edad-00a1-415b-993b-220ff8afcc16"
      },
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(dfdemocrat['handicappedInfants'],dfdemocrat['handicappedInfants'], nan_policy='omit',)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=0.0, pvalue=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "cHWUYukuwxDs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using hypothesis testing, find an issue that democrats support more than republicans with p < 0.01"
      ]
    },
    {
      "metadata": {
        "id": "a5R5waW_wzy3",
        "colab_type": "code",
        "outputId": "2366ea6d-7195-4c96-b525-c2a03de1078f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Issues supported by more Dem's than GOP p_value < 0.01\")\n",
        "\n",
        "for col in dfdemocrat.columns.values:\n",
        "  if col != \"party\":\n",
        "    statistics, pvalue = stats.ttest_ind(dfdemocrat[col], \n",
        "                          dfrepublican[col], \n",
        "                          nan_policy='omit',\n",
        "                          equal_var=True)\n",
        "    if statistics > 0 and pvalue < 0.01:\n",
        "      print(\"{:>40} {:10.3} {:>15.2}\".format(col, statistics, pvalue))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Issues supported by more Dem's than GOP p_value < 0.01\n",
            "                      handicappedInfants       9.21         1.6e-18\n",
            "       adoption-of-the-budget-resolution       23.2         2.1e-77\n",
            "                 anti-satellite-test-ban       12.5         8.5e-31\n",
            "               aid-to-nicaraguan-contras       18.1         2.8e-54\n",
            "                              mx-missile       16.4           5e-47\n",
            "            synfuels-corporation-cutback       8.29         1.6e-15\n",
            "                       duty-free-exports       12.9           6e-32\n",
            "  export-administration-act-south-africa       6.85         3.7e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VOkvT0WcxRdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using hypothesis testing, find an issue that republicans support more than democrats with p < 0.01"
      ]
    },
    {
      "metadata": {
        "id": "uXWZJmfJxGQV",
        "colab_type": "code",
        "outputId": "3eae3a5c-bd96-4b87-aede-a093f8a05cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Issues with more GOP support than Dem's with p-value < 0.01\")\n",
        "\n",
        "for col in dfdemocrat.columns.values:\n",
        "  if col != \"party\":\n",
        "    statistics, pvalue = stats.ttest_ind(dfdemocrat[col], \n",
        "                          dfrepublican[col], \n",
        "                          nan_policy='omit',\n",
        "                          equal_var=True)\n",
        "    if statistics < 0 and pvalue < 0.01:\n",
        "      print(\"{:>40} {:10.3} {:>15.2}\".format(col, statistics, pvalue))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Issues with more GOP support than Dem's with p-value < 0.01\n",
            "                    physician-fee-freeze      -49.4          2e-177\n",
            "                         el-salvador-aid      -21.1         5.6e-68\n",
            "             religious-groups-in-schools      -9.74         2.4e-20\n",
            "                      education-spending      -20.5         1.9e-64\n",
            "                  superfund-right-to-sue      -13.5         1.2e-34\n",
            "                                   crime      -16.3           1e-46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rrE6hS6CxHg1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using hypothesis testing, find an issue where the difference between republicans and democrats has p > 0.1\n",
        "(i.e. there may not be much of a difference)"
      ]
    },
    {
      "metadata": {
        "id": "X__rCcnyx9Az",
        "colab_type": "code",
        "outputId": "4228e0a7-c4c4-46f1-b847-704b4cf0a1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Issues where the difference between republicans and democrats has p > 0.1\")\n",
        "print(\"(i.e. there may not be much of a difference)\")\n",
        "for col in dfdemocrat.columns.values:\n",
        "  if col != \"classname\":\n",
        "    statistics, pvalue = stats.ttest_ind(dfdemocrat[col], \n",
        "                          dfrepublican[col], \n",
        "                          nan_policy='omit',\n",
        "                          equal_var=True)\n",
        "    if pvalue > 0.01:\n",
        "      print(\"{:40} {:<18.3} {:.4}\".format(col, statistics, pvalue))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Issues where the difference between republicans and democrats has p > 0.1\n",
            "(i.e. there may not be much of a difference)\n",
            "water-project-cost-sharing               -0.089             0.9292\n",
            "immigration                              -1.74              0.0833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xay9uQP142l8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Interview questions\n",
        "What is Frequency Perspective\n",
        "\n",
        "An interpretation of probability that defines an event's probability as the limit of its relative frequency in a large number of trials\n",
        "\n",
        " What is P-Value?\n",
        "\n",
        "Probability Value\n",
        " used in hypothesis testing to determine if null hypothesis is rejected or we fail to reject it\n",
        "\n",
        " What is Ttest\n",
        " \n",
        " A type of inferential statistic which is used to determine if there is a significant difference between the means of two groups which may be related\n",
        "\n",
        " What is Null Hypothesis(H0)?\n",
        " \n",
        " Default position that there is no relationship between two measured phenomena. A null hypothesis is a type of hypothesis used in statistics that proposes no statistical significance exists in a set of given observations. The null hypothesis attempts to show that no variation exists between variables OR that a single variable is no different than its mean. H0 is presumed to be true until statistical evidence nullifies it for an alternative hypothesis.\n",
        "\n",
        " \n",
        " What is Degree of Freedom?\n",
        " Freedom to Vary"
      ]
    }
  ]
}